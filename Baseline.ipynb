{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-L-i-1/CS231N-Final-Project/blob/main/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model\n",
        "\n",
        "We will be using SmolVLM"
      ],
      "metadata": {
        "id": "ZuCy0FlUTdbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hf_xet\n",
        "!pip install flash-attn"
      ],
      "metadata": {
        "id": "pnITa0s9zWsz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLErB_vyzBj4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-500M-Instruct\")\n",
        "model = AutoModelForVision2Seq.from_pretrained(\"HuggingFaceTB/SmolVLM-500M-Instruct\",\n",
        "                                                torch_dtype=torch.bfloat16,\n",
        "                                                _attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\").to(DEVICE)\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Mx33qgqYXYxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Single Image"
      ],
      "metadata": {
        "id": "EXkHHJAZTbMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers.image_utils import load_image\n",
        "\n",
        "# load test image\n",
        "image = Image.open(\"/content/test.png\")\n",
        "\n",
        "question = \"\"\"Given the diagram, list the labels of the circles in order from leftmost to rightmost\n",
        "          (provide name only). You should have all the names included. The name for the cicle corresponds\n",
        "          To the arrow that the name points to.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": question}\n",
        "        ]\n",
        "    },\n",
        "]\n",
        "\n",
        "# prepare inputs\n",
        "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
        "inputs = inputs.to(DEVICE)"
      ],
      "metadata": {
        "id": "2OBGe24_0ypl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate outputs\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=500, do_sample=True)\n",
        "generated_texts = processor.batch_decode(\n",
        "    generated_ids,\n",
        "    skip_special_tokens=True,\n",
        ")\n",
        "\n",
        "print(generated_texts[0])\n"
      ],
      "metadata": {
        "id": "LvAXDA1_06CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Baseline on Dataset"
      ],
      "metadata": {
        "id": "f6mOWIl4TlL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "base_drive_path = '/content/drive/My Drive/CS231N Colabs/dataset'\n",
        "json_file_path = os.path.join(base_drive_path, 'metadata.json')\n",
        "\n",
        "# load in the dataset\n",
        "with open(json_file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "count = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# process all the images\n",
        "for entry in tqdm(data, desc=\"Processing Images\"):\n",
        "  count += 1\n",
        "  if count > 250:\n",
        "      break\n",
        "  image_relative_path = entry['image_path']\n",
        "  image_full_path = os.path.join('/content/drive/My Drive/CS231N Colabs', image_relative_path)\n",
        "\n",
        "  image = Image.open(image_full_path)\n",
        "\n",
        "  question = \"\"\"Given the diagram, list the labels of the circles in order from leftmost to rightmost\n",
        "            (provide name only)\"\"\"\n",
        "\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"image\"},\n",
        "              {\"type\": \"text\", \"text\": question}\n",
        "          ]\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  # prepare inputs\n",
        "  prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "  inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
        "  inputs = inputs.to(DEVICE)\n",
        "\n",
        "  # generate outputs\n",
        "  with torch.no_grad():\n",
        "      generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
        "  generated_texts = processor.batch_decode(\n",
        "      generated_ids,\n",
        "      skip_special_tokens=True,\n",
        "  )\n",
        "\n",
        "  # process the output\n",
        "  predicted_order = generated_texts[0].strip()\n",
        "  predicted_order = predicted_order.split(\"Assistant:\")[-1].strip()\n",
        "  predicted_order = [name.strip() for name in predicted_order.split(\",\")]\n",
        "\n",
        "  expected_order = entry['order']\n",
        "\n",
        "  if predicted_order == expected_order:\n",
        "    correct += 1\n",
        "  total += 1\n",
        "\n",
        "print(f\"Accuracy: {correct / total}\")"
      ],
      "metadata": {
        "id": "TwV9UqTPTn4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# If you have a `dataset/` folder, list that too\n",
        "dataset_path = '/content/drive/My Drive/CS231N Colabs/dataset'\n",
        "os.listdir(dataset_path)\n",
        "print(\"image_0.png\" in os.listdir(dataset_path))"
      ],
      "metadata": {
        "id": "WwzTrBuXU1bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Supervised Fine Tuning w/ Cross Entropy Loss\n",
        "\n",
        "CS231N Colabs/dataset - 2500 images\n",
        "2000 train, 250 val, 250 test\n",
        "\n",
        "0-1999, 2000-2249, 2250-2499\n",
        "\n"
      ],
      "metadata": {
        "id": "geCuQuBdKc1l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkMCJX-JKcGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}